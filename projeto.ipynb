{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a7422ec",
   "metadata": {},
   "source": [
    "# Levantamento da comunidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "77e62279",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import fitz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7453946f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pasta = os.getcwd()\n",
    "\n",
    "pasta = os.path.join(pasta, \"..\")\n",
    "\n",
    "arquivo_excel = os.path.join(pasta, \"Participants - Info - Teste.xlsx\")\n",
    "\n",
    "sheets = pd.ExcelFile(arquivo_excel).sheet_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7eb3ff",
   "metadata": {},
   "source": [
    "## total de entrevistas com profundidade transcritas e grupos focais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "95f7cd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "arquivos_docx = []\n",
    "\n",
    "for nome_arquivo in os.listdir(pasta):\n",
    "    if nome_arquivo.endswith(\".docx\"):\n",
    "        arquivos_docx.append(nome_arquivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7eba94c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Local e diários</th>\n",
       "      <th>Quantidade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anchieta</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Paraisópolis</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>União</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Taquaril</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vitória</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Transcrição GF Anchieta</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Transcrição GF União</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Transcrição GF Paraisópolis</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Transcrição GF Taquaril</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Transcrição GF Vitória</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20210324 - SP - InterGF1(TRANSCRIPT).docx</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20210505 - BH - InterGF1(TRANSCRIPT).docx</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20210511 - BH - InterGF2(TRANSCRIPT).docx</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20213003 - SP - InterGF2 (Transcript).docx</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>S23513J02 - 20200827 - Heliopolis - Cleide.docx</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>S23513J04 - 20200828 - Jardim Colombo - Ester....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>S23513J06 - 20200901 - Cidade Tiradentes - Rub...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>S23513J08 - 20201119 - Aglomerado - Kika (p.1)...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>S23513J09 - 20201119 - Aglomerado - Kika (p.2)...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>S23513J18 - 20210202 - Aglomerado - Rosana (Ka...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>S23513J21 - 20210204 - Aglomerado -  Scheyla.docx</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>S23513J48 - 20210526 - Prefeitura BH – Daniela...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Local e diários  Quantidade\n",
       "0                                            Anchieta          12\n",
       "1                                       Paraisópolis          12\n",
       "2                                               União          12\n",
       "3                                            Taquaril          19\n",
       "4                                             Vitória          21\n",
       "5                             Transcrição GF Anchieta           4\n",
       "6                               Transcrição GF União           4\n",
       "7                         Transcrição GF Paraisópolis           4\n",
       "8                             Transcrição GF Taquaril           3\n",
       "9                              Transcrição GF Vitória           4\n",
       "10          20210324 - SP - InterGF1(TRANSCRIPT).docx           1\n",
       "11          20210505 - BH - InterGF1(TRANSCRIPT).docx           1\n",
       "12          20210511 - BH - InterGF2(TRANSCRIPT).docx           1\n",
       "13         20213003 - SP - InterGF2 (Transcript).docx           1\n",
       "14    S23513J02 - 20200827 - Heliopolis - Cleide.docx           1\n",
       "15  S23513J04 - 20200828 - Jardim Colombo - Ester....           1\n",
       "16  S23513J06 - 20200901 - Cidade Tiradentes - Rub...           1\n",
       "17  S23513J08 - 20201119 - Aglomerado - Kika (p.1)...           1\n",
       "18  S23513J09 - 20201119 - Aglomerado - Kika (p.2)...           1\n",
       "19  S23513J18 - 20210202 - Aglomerado - Rosana (Ka...           1\n",
       "20  S23513J21 - 20210204 - Aglomerado -  Scheyla.docx           1\n",
       "21  S23513J48 - 20210526 - Prefeitura BH – Daniela...           1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vamos ver a quantidade de transcrições de GF e entrevistas sem levar em consideração se a pessoa participou ou nao do projeto\n",
    "\n",
    "locais_quantidade_transcricoes= {\n",
    "    'Anchieta':0,\n",
    "    'Paraisópolis':0,\n",
    "    'União':0,\n",
    "    'Taquaril':0,\n",
    "    'Vitória':0,\n",
    "    'Transcrição GF Anchieta' : 0,\n",
    "    'Transcrição GF União' : 0,\n",
    "    'Transcrição GF Paraisópolis' : 0,\n",
    "    'Transcrição GF Taquaril' : 0,\n",
    "    'Transcrição GF Vitória' : 0,\n",
    "}\n",
    "\n",
    "\n",
    "for arquivo in arquivos_docx:\n",
    "\n",
    "    if('GF' in arquivo):\n",
    "        if ('Anchieta' in arquivo):\n",
    "            locais_quantidade_transcricoes['Transcrição GF Anchieta'] += 1\n",
    "        elif ('Paraisópolis' in arquivo):\n",
    "            locais_quantidade_transcricoes['Transcrição GF Paraisópolis'] += 1\n",
    "        elif ('União' in arquivo):\n",
    "            locais_quantidade_transcricoes['Transcrição GF União'] += 1\n",
    "        elif ('Taquaril' in arquivo):\n",
    "            locais_quantidade_transcricoes['Transcrição GF Taquaril'] += 1\n",
    "        elif ('Vitória' in arquivo):\n",
    "            locais_quantidade_transcricoes['Transcrição GF Vitória'] += 1\n",
    "        else:\n",
    "            locais_quantidade_transcricoes[arquivo] = 1\n",
    "    \n",
    "    elif ('SPA' in arquivo) or ('Anchieta' in arquivo):\n",
    "        locais_quantidade_transcricoes['Anchieta'] += 1\n",
    "    elif ('SPP' in arquivo) or ('Paraisópolis' in arquivo) or ('Paraisopolis' in arquivo):\n",
    "        locais_quantidade_transcricoes['Paraisópolis'] += 1\n",
    "    elif ('SPU' in arquivo) or ('União' in arquivo) or ('União' in arquivo) or ('Uniao' in arquivo):\n",
    "        locais_quantidade_transcricoes['União'] += 1\n",
    "    elif ('BHT' in arquivo) or ('Taquaril' in arquivo):\n",
    "        locais_quantidade_transcricoes['Taquaril'] += 1\n",
    "    elif ('BHV' in arquivo) or ('Vitória' in arquivo) or ('Vitoria' in arquivo) or ('Vitória ' in arquivo):\n",
    "        locais_quantidade_transcricoes['Vitória'] += 1\n",
    "    else:\n",
    "        if arquivo not in locais_quantidade_transcricoes:\n",
    "            locais_quantidade_transcricoes[arquivo] = 1\n",
    "        else:\n",
    "            locais_quantidade_transcricoes[arquivo] += 1\n",
    "\n",
    "locais_quantidade_transcricoes = pd.DataFrame(list(locais_quantidade_transcricoes.items()), columns=['Local e diários', 'Quantidade'])\n",
    "locais_quantidade_transcricoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "970d2bd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locais_quantidade_transcricoes.Quantidade.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2b217ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nomes = pd.read_excel(arquivo_excel, sheet_name='PSEUDONYMS')\n",
    "nome = nomes.iloc[:,2].tolist()\n",
    "codigo = nomes.iloc[:,3].tolist()\n",
    "nome = ['Silvia', 'Nataly', 'Raiane', 'Sandra', 'Francisca', 'Rosalva', 'Leide', 'Caroline', 'Betânia', 'Marcelo', 'Gislene', 'Arlete', 'Rebeca', 'Camila', 'Helena', 'Hilda', 'Franciele', 'Roberto', 'Sueli', 'Heloísa', 'Janaína', 'Ceres', 'Daniela', 'Carla', 'Leilane', 'Luma', 'Adriele', 'Greice', 'Meire', 'Cleide', 'Josiane', 'Claudia', 'Simone', 'Ivanete', 'Fabíola', 'Marina', 'Zuleika', 'Jéssica', 'Denise', 'Fabrícia', 'Lídia', 'Estela', 'Fátima', 'Leandra', 'Lúcia', 'Márcia', 'Cíntia', 'Elisa', 'Ketlen', 'Aline', 'Melissa', 'Gabriela', 'Tainara', 'Naiara', 'Nair', 'Geize', 'Marlize', 'Patrícia', 'Luan', 'Rita', 'Valmir', 'Suzana', 'Tayla', 'Carmélia', 'Bete', 'Darcy', 'Isabel', 'Natasha']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7807c0e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20210128 - SPP11 - Franciele (Interview 2).docx\n",
      "20210128 - SPU19 - Cleide (Interview 2).docx\n",
      "20210129 - SPP10 - Hilda (Interview 2).docx\n",
      "20210202 - SPP09 - Helena (Interview 2).docx\n",
      "20210205 - SPP08 - Camila (Interview 2).docx\n",
      "20210205 - SPP29 - Janaína (Interview 2).docx\n",
      "entrei else2 20210205 - SPP29 - Janaína (Interview 2).docx\n",
      "20210205 - SPP33 - Leilane (Interview 2).docx\n",
      "20210205 - SPU18 - Meire (Interview 2).docx\n",
      "20210213 - SPA03 - Raiane (Interview 2).docx\n",
      "20210216 - SPA04 - Sandra (Interview 2).docx\n",
      "20210216 - SPA05 - Francisca (Interview 2).docx\n",
      "20210220 - BHV56 - Nair (Interview 1).docx\n",
      "20210220 - BHV57 - Geize (Interview 1).docx\n",
      "20210221 - BHV60 - Luan (Interview 1).docx\n",
      "20210221 - BHV61 - Rita (Interview 1).docx\n",
      "20210223 - BHV58 - Marlize (Interview 1).docx\n",
      "20210223 - SPU16 - Adriele (Interview 2).docx\n",
      "20210225 - SPP32 - Carla (Interview 2).docx\n",
      "20210225 - SPU15 - Luma (Interview 2).docx\n",
      "20210226 - SPP28 - Heloísa (Interview 2).docx\n",
      "20210226 - SPU35 - Ivanete (Interview 2).docx\n",
      "20210227 - SPA02 - Nataly (Interview 2).docx\n",
      "202102XX - BHV59 - Patrícia (Interview 1).docx\n",
      "entrei else2 202102XX - BHV59 - Patrícia (Interview 1).docx\n",
      "20210301 - SPP31 - Daniela (Interview 2).docx\n",
      "20210303 - SPP30 - Ceres (Interview 2).docx\n",
      "20210304 - BHT45 - Leandra (Interview 2).docx\n",
      "20210305 - SPU37 - Marina (Interview 2).docx\n",
      "20210306 - SPU38 - Zuleika (Interview 2).docx\n",
      "20210306 - SPU40 - Denise (Interview 2).docx\n",
      "20210308 - SPU34 - Simone (Interview 2).docx\n",
      "20210311 - SPA06 - Rosalva (Interview 2).docx\n",
      "20210312 - SPA22 - Caroline (Interview 2).docx\n",
      "20210312 - SPA24 - Marcelo (Interview 2).docx\n",
      "20210313 - SPA27 - Rebeca (Interview 2).docx\n",
      "20210314 - SPA01 - Silvia (Interview 2).docx\n",
      "20210320 - BHV65 - Carmélia (Interview 1).docx\n",
      "entrei else2 20210320 - BHV65 - Carmélia (Interview 1).docx\n",
      "20210320 - BHV69 - Natasha (Interview 1).docx\n",
      "20210322 - BHT48 - Cíntia (Interview 2).docx\n",
      "20210326 - BHV63 - Suzana (Interview 1).docx\n",
      "20210329 - SPU39 - Jéssica (Interview 2).docx\n",
      "20210330 - BHT44 - Fátima (Interview 2).docx\n",
      "20210401 - BHT43 - Estela (Interview 2).docx\n",
      "20210413 - BHT47 - Marcia (Interview 2).docx\n",
      "entrei else2 20210413 - BHT47 - Marcia (Interview 2).docx\n",
      "20210422 - BHT42 - Lídia (Interview 2).docx\n",
      "20210422 - BHT50 - Ketlen (Interview 2).docx\n",
      "20210422 - BHT51 - Aline (Interview 2).docx\n",
      "20210423 - BHT52 - Melissa (Interview 2).docx\n",
      "20210424 - BHT53 - Gabriela (Interview 2).docx\n",
      "20210424 - BHT54 - Tainara (Interview 2).docx\n",
      "20210428 - BHT55 - Naiara (Interview 2).docx\n",
      "20210XXX - BHV56 - Nair (Interview 2).docx\n",
      "20210XXX - BHV65 - Carmélia (Interview 2).docx\n",
      "entrei else2 20210XXX - BHV65 - Carmélia (Interview 2).docx\n",
      "20219203 - SPU17 - Greice (Interview 2).docx\n",
      "2021XXXX - BHV57 - Geize (Interview 2).docx\n",
      "2021XXXX - BHV60 - Luan (Interview 2).docx\n",
      "2021XXXX - BHV61 - Rita (Interview 2).docx\n",
      "2021XXXX - BHV63 - Suzana (Interview 2).docx\n",
      "2021XXXX - BHV64 - Tayla (Interview 1).docx\n",
      "2021XXXX - BHV64 - Tayla (Interview 2).docx\n",
      "2021XXXX - BHV69 - Natasha (Interview 2).docx\n",
      "S23996J17 - BHV62 (Interview 1).docx\n",
      "entrei else2 S23996J17 - BHV62 (Interview 1).docx\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Local e diários</th>\n",
       "      <th>Quantidade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anchieta</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Paraisópolis</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>União</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Taquaril</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vitória</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Transcrição GF Anchieta</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Transcrição GF União</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Transcrição GF Paraisópolis</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Transcrição GF Taquaril</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Transcrição GF Vitória</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20210324 - SP - InterGF1(TRANSCRIPT).docx</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20210505 - BH - InterGF1(TRANSCRIPT).docx</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20210511 - BH - InterGF2(TRANSCRIPT).docx</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20213003 - SP - InterGF2 (Transcript).docx</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>S23513J01 - 20200826 - Anchieta - Flash.docx</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>S23513J02 - 20200827 - Heliopolis - Cleide.docx</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>S23513J03 - 20200827 - Uniao - Hermes.docx</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>S23513J04 - 20200828 - Jardim Colombo - Ester....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>S23513J05 - 20200828 - Paraisopolis - Juliana....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>S23513J06 - 20200901 - Cidade Tiradentes - Rub...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>S23513J07 - 20201013 - Vitoria - Adao.docx</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>S23513J08 - 20201119 - Aglomerado - Kika (p.1)...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>S23513J09 - 20201119 - Aglomerado - Kika (p.2)...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>S23513J10 - 20201125 - Vitoria - Paulinha.docx</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>S23513J18 - 20210202 - Aglomerado - Rosana (Ka...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>S23513J19 - 20210203 - Taquaril - Edneia (p.1)...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>S23513J20 - 20210203 - Taquaril - Edneia (p.2)...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>S23513J21 - 20210204 - Aglomerado -  Scheyla.docx</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>S23513J25 - 20210217 - Taquaril - W2 (Casa do ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>S23513J30 - 20210306 - Paraisopolis - Felipe (...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>S23513J33 - 20210319 - Anchieta - Buiu (Projet...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>S23513J36 - 20210325 - Anchieta - Anderson Pe ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>S23513J44 – 20210513 – Taquaril – Edineia.docx</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>S23513J45 - 20210518 - Taquaril - Rosinele (CU...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>S23513J46 - 20210518 - Taquaril - Sandro (Casa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>S23513J47 - 20210520 - Taquaril - Luis e Karol...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>S23513J48 - 20210526 - Prefeitura BH – Daniela...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Local e diários  Quantidade\n",
       "0                                            Anchieta           9\n",
       "1                                       Paraisópolis          10\n",
       "2                                               União          11\n",
       "3                                            Taquaril          12\n",
       "4                                             Vitória          19\n",
       "5                             Transcrição GF Anchieta           4\n",
       "6                               Transcrição GF União           4\n",
       "7                         Transcrição GF Paraisópolis           4\n",
       "8                             Transcrição GF Taquaril           3\n",
       "9                              Transcrição GF Vitória           4\n",
       "10          20210324 - SP - InterGF1(TRANSCRIPT).docx           1\n",
       "11          20210505 - BH - InterGF1(TRANSCRIPT).docx           1\n",
       "12          20210511 - BH - InterGF2(TRANSCRIPT).docx           1\n",
       "13         20213003 - SP - InterGF2 (Transcript).docx           1\n",
       "14       S23513J01 - 20200826 - Anchieta - Flash.docx           1\n",
       "15    S23513J02 - 20200827 - Heliopolis - Cleide.docx           1\n",
       "16         S23513J03 - 20200827 - Uniao - Hermes.docx           1\n",
       "17  S23513J04 - 20200828 - Jardim Colombo - Ester....           1\n",
       "18  S23513J05 - 20200828 - Paraisopolis - Juliana....           1\n",
       "19  S23513J06 - 20200901 - Cidade Tiradentes - Rub...           1\n",
       "20         S23513J07 - 20201013 - Vitoria - Adao.docx           1\n",
       "21  S23513J08 - 20201119 - Aglomerado - Kika (p.1)...           1\n",
       "22  S23513J09 - 20201119 - Aglomerado - Kika (p.2)...           1\n",
       "23     S23513J10 - 20201125 - Vitoria - Paulinha.docx           1\n",
       "24  S23513J18 - 20210202 - Aglomerado - Rosana (Ka...           1\n",
       "25  S23513J19 - 20210203 - Taquaril - Edneia (p.1)...           1\n",
       "26  S23513J20 - 20210203 - Taquaril - Edneia (p.2)...           1\n",
       "27  S23513J21 - 20210204 - Aglomerado -  Scheyla.docx           1\n",
       "28  S23513J25 - 20210217 - Taquaril - W2 (Casa do ...           1\n",
       "29  S23513J30 - 20210306 - Paraisopolis - Felipe (...           1\n",
       "30  S23513J33 - 20210319 - Anchieta - Buiu (Projet...           1\n",
       "31  S23513J36 - 20210325 - Anchieta - Anderson Pe ...           1\n",
       "32     S23513J44 – 20210513 – Taquaril – Edineia.docx           1\n",
       "33  S23513J45 - 20210518 - Taquaril - Rosinele (CU...           1\n",
       "34  S23513J46 - 20210518 - Taquaril - Sandro (Casa...           1\n",
       "35  S23513J47 - 20210520 - Taquaril - Luis e Karol...           1\n",
       "36  S23513J48 - 20210526 - Prefeitura BH – Daniela...           1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Vamos ver a quantidade de transcrições de GF e entrevistas levando em consideração se a pessoa participou ou nao do projeto\n",
    "\n",
    "locais_quantidade_transcricoes2 = {\n",
    "    'Anchieta':0,\n",
    "    'Paraisópolis':0,\n",
    "    'União':0,\n",
    "    'Taquaril':0,\n",
    "    'Vitória':0,\n",
    "    'Transcrição GF Anchieta' : 0,\n",
    "    'Transcrição GF União' : 0,\n",
    "    'Transcrição GF Paraisópolis' : 0,\n",
    "    'Transcrição GF Taquaril' : 0,\n",
    "    'Transcrição GF Vitória' : 0,\n",
    "}\n",
    "\n",
    "contador = 0 \n",
    "pessoas = 0\n",
    "lista_pessoas = []\n",
    "BHV = 0\n",
    "BHT =0\n",
    "\n",
    "for arquivo in arquivos_docx:\n",
    "    contador +=1\n",
    "    #print(arquivo)\n",
    "\n",
    "    #dados = pd.DataFrame(arquivo)\n",
    "\n",
    "    if('GF' in arquivo):\n",
    "        if ('Anchieta' in arquivo):\n",
    "            locais_quantidade_transcricoes2['Transcrição GF Anchieta'] += 1\n",
    "        elif ('Paraisópolis' in arquivo):\n",
    "            locais_quantidade_transcricoes2['Transcrição GF Paraisópolis'] += 1\n",
    "        elif ('União' in arquivo):\n",
    "            locais_quantidade_transcricoes2['Transcrição GF União'] += 1\n",
    "        elif ('Taquaril' in arquivo):\n",
    "            locais_quantidade_transcricoes2['Transcrição GF Taquaril'] += 1\n",
    "        elif ('Vitória' in arquivo):\n",
    "            locais_quantidade_transcricoes2['Transcrição GF Vitória'] += 1\n",
    "        else:\n",
    "            locais_quantidade_transcricoes2[arquivo] = 1\n",
    "\n",
    "\n",
    "    elif any(palavra in arquivo for palavra in codigo):\n",
    "        print(arquivo)\n",
    "        if any(palavra in arquivo for palavra in nome):\n",
    "            pessoas +=1\n",
    "            if ('SPA' in arquivo) or ('Anchieta' in arquivo):\n",
    "                locais_quantidade_transcricoes2['Anchieta'] += 1\n",
    "            elif ('SPP' in arquivo) or ('Paraisópolis' in arquivo) or ('Paraisopolis' in arquivo):\n",
    "                locais_quantidade_transcricoes2['Paraisópolis'] += 1\n",
    "            elif ('SPU' in arquivo) or ('União' in arquivo) or ('União' in arquivo) or ('Uniao' in arquivo):\n",
    "                locais_quantidade_transcricoes2['União'] += 1\n",
    "            elif ('BHT' in arquivo) or ('Taquaril' in arquivo):\n",
    "                locais_quantidade_transcricoes2['Taquaril'] += 1\n",
    "                BHT+=1\n",
    "            elif ('BHV' in arquivo) or ('Vitória' in arquivo) or ('Vitoria' in arquivo) or ('Vitória ' in arquivo) or ('BHV62' in arquivo):\n",
    "                locais_quantidade_transcricoes2['Vitória'] += 1\n",
    "                BHV +=1\n",
    "            elif('TRANSCRIPT' in arquivo) or (''):\n",
    "                locais_quantidade_transcricoes2['TRANSCRIPT'] += 1\n",
    "            else:\n",
    "                locais_quantidade_transcricoes2[f'não está com nome no excel, mas é de um lugar de pesquisa: {arquivo}'] = 1\n",
    "        else:\n",
    "            print(f'entrei else2 {arquivo}')\n",
    "            if ('SPA' in arquivo) or ('Anchieta' in arquivo):\n",
    "                locais_quantidade_transcricoes2['Anchieta'] += 1\n",
    "            elif ('SPP' in arquivo) or ('Paraisópolis' in arquivo) or ('Paraisopolis' in arquivo):\n",
    "                locais_quantidade_transcricoes2['Paraisópolis'] += 1\n",
    "            elif ('SPU' in arquivo) or ('União' in arquivo) or ('União' in arquivo) or ('Uniao' in arquivo):\n",
    "                locais_quantidade_transcricoes2['União'] += 1\n",
    "            elif ('BHT' in arquivo) or ('Taquaril' in arquivo):\n",
    "                locais_quantidade_transcricoes2['Taquaril'] += 1\n",
    "                BHT+=1\n",
    "            elif ('BHV' in arquivo) or ('Vitória' in arquivo) or ('Vitoria' in arquivo) or ('Vitória ' in arquivo) or ('BHV62' in arquivo):\n",
    "                locais_quantidade_transcricoes2['Vitória'] += 1\n",
    "                BHV +=1\n",
    "            elif('TRANSCRIPT' in arquivo) or (''):\n",
    "                locais_quantidade_transcricoes2['TRANSCRIPT'] += 1\n",
    "            else:\n",
    "                locais_quantidade_transcricoes2[arquivo] = 1\n",
    "\n",
    "    else:\n",
    "        locais_quantidade_transcricoes2[arquivo] = 1\n",
    "    \n",
    "\n",
    "\n",
    "locais_quantidade_transcricoes2 = pd.DataFrame(list(locais_quantidade_transcricoes2.items()), columns=['Local e diários', 'Quantidade'])\n",
    "display(locais_quantidade_transcricoes2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d07b3b58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locais_quantidade_transcricoes2.Quantidade.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "79b48e98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(arquivos_docx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861c28e7",
   "metadata": {},
   "source": [
    "## Total de diários alimentares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6c323d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " não existe: PSEUDONYMS\n",
      " não existe: SPU35\n",
      " não existe: BHT43\n",
      " não existe: BHT53\n"
     ]
    }
   ],
   "source": [
    "# Total de diários alimentares \n",
    "\n",
    "nada = 0\n",
    "contador = 0\n",
    "\n",
    "locais_quantidade_diarios = {\n",
    "    'nada' : 0\n",
    "}\n",
    "\n",
    "for sheet in sheets:\n",
    "    dados = pd.read_excel(arquivo_excel, sheet_name=sheet, header=None)\n",
    "    dados = pd.DataFrame(dados)\n",
    "    dados[5] = \"\"  \n",
    "\n",
    "    local = dados.iloc[3, 2]\n",
    "    \n",
    "    caminho_arquivo = os.path.join(pasta, f\"{sheet}.pdf\")\n",
    "        \n",
    "    if os.path.exists(caminho_arquivo):\n",
    "        contador += 1            \n",
    "    else:\n",
    "        nada += 1\n",
    "        locais_quantidade_diarios['nada'] +=1\n",
    "        print(f' não existe: {sheet}')\n",
    "    \n",
    "    if local not in locais_quantidade_diarios.keys():\n",
    "        locais_quantidade_diarios[local] = 1\n",
    "    else:\n",
    "        locais_quantidade_diarios[local] += 1\n",
    "\n",
    "\n",
    "locais_quantidade_diarios = pd.DataFrame(list(locais_quantidade_diarios.items()), columns=['Local', 'Quantidade'])\n",
    "\n",
    "locais_quantidade_diarios['Local'] = locais_quantidade_diarios['Local'].replace({\n",
    "    'União': 'União de Vila Nova',\n",
    "    'União de Vila Nov': 'União de Vila Nova'\n",
    "})\n",
    "\n",
    "locais_quantidade_diarios = locais_quantidade_diarios.groupby('Local', as_index=False).sum()\n",
    "\n",
    "locais_quantidade_diarios = locais_quantidade_diarios.drop(3)\n",
    "\n",
    "locais_quantidade_diarios = locais_quantidade_diarios.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "023e3261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " não existe: PSEUDONYMS\n",
      "SPA01\n",
      "SPA02\n",
      "SPA03\n",
      "SPA04\n",
      "SPA05\n",
      "SPA06\n",
      "SPA07\n",
      "SPA22\n",
      "INCOMPLETO: SPA23\n",
      "SPA23\n",
      "SPA24\n",
      "SPA25\n",
      "SPA26\n",
      "SPA27\n",
      "SPP08\n",
      "SPP09\n",
      "SPP10\n",
      "SPP11\n",
      "SPP13\n",
      "SPP14\n",
      "SPP28\n",
      "SPP29\n",
      "SPP30\n",
      "SPP31\n",
      "SPP32\n",
      "SPP33\n",
      "SPU15\n",
      "SPU16\n",
      "SPU17\n",
      "SPU18\n",
      "SPU19\n",
      "SPU20\n",
      "SPU21\n",
      "SPU34\n",
      " não existe: SPU35\n",
      "SPU36\n",
      "SPU37\n",
      "SPU38\n",
      "SPU39\n",
      "SPU40\n",
      "BHT41\n",
      "BHT42\n",
      " não existe: BHT43\n",
      "BHT44\n",
      "BHT45\n",
      "BHT46\n",
      "BHT47\n",
      "BHT48\n",
      "INCOMPLETO: BHT49\n",
      "BHT49\n",
      "BHT50\n",
      "BHT51\n",
      "BHT52\n",
      " não existe: BHT53\n",
      "BHT54\n",
      "BHT55\n",
      "BHV56\n",
      "BHV57\n",
      "INCOMPLETO: BHV58\n",
      "BHV58\n",
      "BHV59\n",
      "BHV60\n",
      "BHV61\n",
      "BHV62\n",
      "BHV63\n",
      "BHV64\n",
      "BHV65\n",
      "BHV66\n",
      "BHV67\n",
      "BHV68\n",
      "BHV69\n"
     ]
    }
   ],
   "source": [
    "# Total de diários alimentares \n",
    "\n",
    "nada = 0\n",
    "contador = 0\n",
    "\n",
    "locais_quantidade_diarios = {\n",
    "    'nada' : 0\n",
    "}\n",
    "\n",
    "for sheet in sheets:\n",
    "    dados = pd.read_excel(arquivo_excel, sheet_name=sheet, header=None)\n",
    "    dados = pd.DataFrame(dados)\n",
    "\n",
    "\n",
    "    local = dados.iloc[3, 2]\n",
    "    resposta = dados.iloc[4,2]\n",
    "    \n",
    "    caminho_arquivo = os.path.join(pasta, f\"{sheet}.pdf\")\n",
    "\n",
    "    if resposta == 'N':\n",
    "        print(f'INCOMPLETO: {sheet}')\n",
    "        \n",
    "    if os.path.exists(caminho_arquivo):\n",
    "        contador += 1    \n",
    "        if local not in locais_quantidade_diarios.keys():\n",
    "            locais_quantidade_diarios[local] = 1\n",
    "            print(sheet)\n",
    "        else:\n",
    "            locais_quantidade_diarios[local] += 1 \n",
    "            print(sheet)       \n",
    "    else:\n",
    "        nada += 1\n",
    "        locais_quantidade_diarios['nada'] +=1\n",
    "        print(f' não existe: {sheet}')\n",
    "    \n",
    "\n",
    "locais_quantidade_diarios = pd.DataFrame(list(locais_quantidade_diarios.items()), columns=['Local', 'Quantidade'])\n",
    "\n",
    "locais_quantidade_diarios['Local'] = locais_quantidade_diarios['Local'].replace({\n",
    "    'União': 'União de Vila Nova',\n",
    "    'União de Vila Nov': 'União de Vila Nova'\n",
    "})\n",
    "\n",
    "locais_quantidade_diarios = locais_quantidade_diarios.groupby('Local', as_index=False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e9ff2f6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locais_quantidade_diarios['Quantidade'].sum() - 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0568850e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INCOMPLETO: SPA23, BHT49, BHV58 \n",
      " SEM CONCLUSÃO: BHT51 \n",
      " NÃO ENVIADOS: SPU35, BHT43, BHT53\n"
     ]
    }
   ],
   "source": [
    "print('INCOMPLETO: SPA23, BHT49, BHV58 \\n',\n",
    "      'SEM CONCLUSÃO: BHT51 \\n',\n",
    "      'NÃO ENVIADOS: SPU35, BHT43, BHT53')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "262b7b68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Local</th>\n",
       "      <th>Quantidade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anchieta</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ocupação Vitória</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Paraisópolis</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Taquaril</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>União de Vila Nova</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nada</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Local  Quantidade\n",
       "0            Anchieta          13\n",
       "1    Ocupação Vitória          14\n",
       "2        Paraisópolis          12\n",
       "3            Taquaril          13\n",
       "4  União de Vila Nova          13\n",
       "5                nada           4"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locais_quantidade_diarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3280b202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n"
     ]
    }
   ],
   "source": [
    "print(contador)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786d4253",
   "metadata": {},
   "source": [
    "## Total de fotos enviadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "104d6732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Local</th>\n",
       "      <th>Quantidade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anchieta</td>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Paraisópolis</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>União</td>\n",
       "      <td>266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Taquaril</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vitória</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Local  Quantidade\n",
       "0       Anchieta         237\n",
       "1  Paraisópolis         235\n",
       "2          União         266\n",
       "3       Taquaril         232\n",
       "4        Vitória         210"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sheets = pd.ExcelFile(arquivo_excel).sheet_names\n",
    "\n",
    "locais_quantidade_imagens = {\n",
    "    'Anchieta':0,\n",
    "    'Paraisópolis':0,\n",
    "    'União':0,\n",
    "    'Taquaril':0,\n",
    "    'Vitória':0\n",
    "}\n",
    "\n",
    "\n",
    "for sheet in sheets:\n",
    "    if os.path.exists(os.path.join(pasta, f\"{sheet}.pdf\")):\n",
    "        doc = fitz.open(f\"{sheet}.pdf\")\n",
    "        nome_arquivo = os.path.basename(os.path.join(pasta, f\"{sheet}.pdf\"))\n",
    "\n",
    "        contador_imagens = 0\n",
    "\n",
    "        for i in range(len(doc)):\n",
    "            pagina = doc.load_page(i)\n",
    "            imagens = pagina.get_images(full=True)\n",
    "    \n",
    "            for img_index, img in enumerate(imagens):\n",
    "                xref = img[0]\n",
    "                base_imagem = doc.extract_image(xref)\n",
    "                imagem_extensao = base_imagem[\"ext\"]\n",
    "\n",
    "                if imagem_extensao.lower() == 'png':\n",
    "                    continue\n",
    "                elif imagem_extensao.lower() in ['jpeg', 'jpg']:\n",
    "                    contador_imagens += 1\n",
    "\n",
    "\n",
    "        #print(f'{nome_arquivo} : {contador_imagens}')\n",
    "\n",
    "        if ('SPA' in nome_arquivo):\n",
    "            locais_quantidade_imagens['Anchieta'] += contador_imagens\n",
    "        elif ('SPP' in nome_arquivo):\n",
    "            locais_quantidade_imagens['Paraisópolis'] += contador_imagens\n",
    "        elif ('SPU' in nome_arquivo):\n",
    "            locais_quantidade_imagens['União'] += contador_imagens\n",
    "        elif ('BHT' in nome_arquivo):\n",
    "            locais_quantidade_imagens['Taquaril'] += contador_imagens\n",
    "        elif ('BHV' in nome_arquivo):\n",
    "            locais_quantidade_imagens['Vitória'] += contador_imagens\n",
    "\n",
    "        doc.close()\n",
    "\n",
    "locais_quantidade_imagens = pd.DataFrame(list(locais_quantidade_imagens.items()), columns=['Local', 'Quantidade'])\n",
    "locais_quantidade_imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a1e5b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
